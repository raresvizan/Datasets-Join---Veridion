{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a6d406f-9e77-440e-9a1b-0a380b263223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61c82b2d-f2b7-468a-ab70-4be23f4a80a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_facebook = pd.read_csv('datasets/facebook_dataset.csv',quotechar='\"',escapechar='\\\\',dtype={'phone': str})\n",
    "df_google = pd.read_csv('datasets/google_dataset.csv',quotechar='\"',escapechar='\\\\',dtype={'phone': str,'raw_phone':str})\n",
    "df_website = pd.read_csv('datasets/website_dataset.csv',quotechar='\"',dtype={'phone': str},sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b918c5f-e8b5-4ec6-9e3b-20ca1c43abbb",
   "metadata": {},
   "source": [
    "I decided to join these 3 datasets based on the domain, because all of the datasets had this information and it was the only unique information (domains are unique)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bc4e84d-6d1b-48a2-a701-dde336878fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df_facebook, df_google,how='outer',on='domain')\n",
    "df_merged = pd.merge(df_merged, df_website, left_on='domain', right_on='root_domain',how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeffcc6-5d33-40bc-b8cf-28491a369826",
   "metadata": {},
   "source": [
    "I delete the columns that I do not use. I keep only the information that interests us the most (category, location,phone,company names). I also deleted the duplicates if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50b38489-0900-4a3e-a818-7947749b04f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.drop(columns=['root_domain','domain','description','email','link','page_type','text','domain_suffix','language','site_name','tld',\n",
    "                        'phone_country_code_x','phone_country_code_y'],inplace=True)\n",
    "df_merged.drop_duplicates(keep='first',inplace=True)\n",
    "df_merged.dropna(inplace=True,how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d7a993-a6ec-400a-b31d-a0d8851f547f",
   "metadata": {},
   "source": [
    "Trust Hierarchy: website > google > facebook\n",
    "1) Company Name: name_y > name_x (I wont include legal_name from website database bc company name many times is different or has multiple names for different products) if there is no name, it will be completed with the legal name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34c8ebaf-8bd1-414c-8c3c-d3147b7027f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_name(row):\n",
    "    if pd.notnull(row['name_y']):\n",
    "        return row['name_y']\n",
    "    elif pd.notnull(row['name_x']):\n",
    "        return row['name_x']\n",
    "    return row['legal_name']\n",
    "\n",
    "df_merged['name'] = df_merged.apply(choose_name,axis=1)\n",
    "df_merged.drop(columns=['name_x','name_y'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1024c8-6c25-4227-a5f2-859e26531f27",
   "metadata": {},
   "source": [
    "2) Phone: the same as name, the phone provided on the website could be different than the one from google when a company has multiple offices. The google dataset provides 2 phones, phone_y > raw_phone bc it is more standardized. If phone_y doesn't exist, will use raw_phone and standardize it later. If raw_phone doesn't exist will use phone bc it comes from website dataset which is safer than facebook dataset. Last option will be facebook dataset, phone_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "622a2936-521b-4905-86b6-f851501a8d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_phone(row):\n",
    "    if pd.notnull(row['phone_y']) and 'E' not in row['phone_y']:\n",
    "        return row['phone_y']\n",
    "    elif pd.notnull(row['raw_phone']) and 'E' not in row['raw_phone']:\n",
    "        return row['raw_phone']\n",
    "    elif pd.notnull(row['phone']) and 'E' not in row['phone']: \n",
    "        return row['phone']\n",
    "    elif pd.notnull(row['phone_x']) and 'E' not in row['phone_x']:\n",
    "        return row['phone_x']\n",
    "    return np.nan\n",
    "\n",
    "df_merged['chosen_phone'] = df_merged.apply(choose_phone,axis=1)\n",
    "df_merged.drop(columns=['phone_x','phone_y','raw_phone','phone'],inplace=True)\n",
    "df_merged.rename(columns={'chosen_phone':'phone'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afef6eac-57c0-4b96-aa91-8b45b388f20a",
   "metadata": {},
   "source": [
    "3) Category: Usually the s_category from website dataset should be accurate in most cases, but as we saw, sometimes a company does multiple things under the same legal name. So, first, if the 'legal_name' doesnt exist we will check the similarity between the 'name' and every category and choose the max value of the ratio. If exists, we will check the similarity between the 'legal_name' and the name we chose the most appropriate. If the ratio is >= 0.5, the 's_category' should match the reality. If not, we will choose the 'category' from google dataset being more accurate than facebook. If it doesn't exist, we will trust the website more than facebook so 's_category'. If it doesnt exist, we will choose 'categories'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c11cbac9-7a75-4b26-995c-75241b5bc0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def choose_category(row): \n",
    "    if pd.isnull(row['legal_name']):\n",
    "        ratio1 = ratio2 = ratio3 = 0\n",
    "        if pd.notnull(row['s_category']):\n",
    "            ratio1 = SequenceMatcher(None,row['s_category'] , row['name']).ratio()\n",
    "        if pd.notnull(row['category']):    \n",
    "            ratio2 = SequenceMatcher(None,row['category'] , row['name']).ratio()\n",
    "        if pd.notnull(row['categories']):\n",
    "            ratio3 = SequenceMatcher(None,row['categories'] , row['name']).ratio()\n",
    "        max_value = max(ratio1,ratio2,ratio3)\n",
    "        if ratio1 == max_value:\n",
    "            return row['s_category']\n",
    "        if ratio2 == max_value:\n",
    "            return row['category']\n",
    "        if ratio3 == max_value:\n",
    "            return row['categories']\n",
    "    if pd.notnull(row['legal_name']) and pd.notnull(row['s_category']): \n",
    "        ratio = SequenceMatcher(None,row['legal_name'] , row['name']).ratio()\n",
    "        if ratio >= 0.5: \n",
    "            return row['s_category']\n",
    "    if pd.notnull(row['category']): \n",
    "        return row['category']\n",
    "    if pd.notnull(row['s_category']):\n",
    "        return row['s_category']\n",
    "    return row['categories']\n",
    "\n",
    "df_merged['chosen_category'] = df_merged.apply(choose_category,axis=1)\n",
    "df_merged.drop(columns=['s_category','category','categories'],inplace=True)\n",
    "df_merged.rename(columns={'chosen_category':'category'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67e37a6-2e6d-46ce-9f2f-42457478eedc",
   "metadata": {},
   "source": [
    "4) Country: We will check the country correctness with the columns: country_code_x, country_name_x, country_code_y, country_name_y. We will include main_country just if others aren't correct bc often companies have the HQ in other countries and multiple offices in others. We will trust google first (_y) if both name and code match, then facebook.\n",
    "   I will use pycountry to check if the country code matches the country name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "537a5247-a87f-4bac-b873-8557acbf9a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry\n",
    "\n",
    "def match_country_code_name(country_code, country_name):\n",
    "    try:\n",
    "        # Look up the country by its code\n",
    "        country = pycountry.countries.get(alpha_2=country_code.upper())\n",
    "        \n",
    "        if country:\n",
    "            # Compare the provided name with the official country name\n",
    "            return country.name.lower() == country_name.lower()\n",
    "        else:\n",
    "            return False\n",
    "    except KeyError:\n",
    "        return False\n",
    "\n",
    "def choose_country(row):\n",
    "    if pd.notnull(row['country_code_y']) and pd.notnull(row['country_name_y']):\n",
    "        if match_country_code_name(row['country_code_y'],row['country_name_y']):\n",
    "            return row['country_name_y']\n",
    "    else:\n",
    "        if pd.notnull(row['country_name_y']):\n",
    "            return row['country_name_y']\n",
    "        if pd.notnull(row['country_code_y']):\n",
    "            country = pycountry.countries.get(alpha_2=row['country_code_y'].upper())\n",
    "            if country:\n",
    "                return country.name.lower()\n",
    "\n",
    "    if pd.notnull(row['country_code_x']) and pd.notnull(row['country_name_x']):\n",
    "        if match_country_code_name(row['country_code_x'],row['country_name_x']):\n",
    "            return row['country_name_x']\n",
    "    else:\n",
    "        if pd.notnull(row['country_name_x']):\n",
    "            return row['country_name_x']\n",
    "        if pd.notnull(row['country_code_x']):\n",
    "            country = pycountry.countries.get(alpha_2=row['country_code_x'].upper())\n",
    "            if country:\n",
    "                return country.name.lower()\n",
    "\n",
    "    return row['main_country']\n",
    "\n",
    "df_merged['country'] = df_merged.apply(choose_country,axis=1)\n",
    "df_merged.drop(columns=['country_code_x', 'country_name_x', 'country_code_y', 'country_name_y','main_country'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ab6257-8070-4fc9-bd1b-0424e1ee74a7",
   "metadata": {},
   "source": [
    "5) Region: we will check every region name if it is part of the country we found previosly using pycountry.subdivisions keeping the same hierarcy google > facebook > website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "296aa6b9-0fb7-4152-bdfd-6f6adab06e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry\n",
    "\n",
    "def is_region_in_country(region_name, country_name):\n",
    "    try:\n",
    "        # Find the country object by name\n",
    "        country = pycountry.countries.get(name=country_name)\n",
    "        if not country:\n",
    "            return False\n",
    "\n",
    "        # Iterate through all subdivisions (regions) in that country\n",
    "        for subdivision in pycountry.subdivisions.get(country_code=country.alpha_2):\n",
    "            if subdivision.name.lower() == region_name.lower():\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    except LookupError:\n",
    "        return False\n",
    "\n",
    "def choose_region(row):\n",
    "    if pd.notnull(row['region_name_y']): \n",
    "        if is_region_in_country(row['region_name_y'],row['country']):\n",
    "            return row['region_name_y']\n",
    "    if pd.notnull(row['region_name_x']): \n",
    "        if is_region_in_country(row['region_name_x'],row['country']):\n",
    "            return row['region_name_x']\n",
    "    if pd.notnull(row['main_region']): \n",
    "        if is_region_in_country(row['main_region'],row['country']):\n",
    "            return row['main_region']\n",
    "    return np.nan\n",
    "\n",
    "df_merged['region'] = df_merged.apply(choose_region, axis=1)\n",
    "df_merged.drop(columns=['region_code_x', 'region_name_x', 'region_code_y', 'region_name_y','main_region'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce09b61-fb37-450c-b15b-0480c292cc22",
   "metadata": {},
   "source": [
    "6) City & Zip Code: based on the previous hierarcy: google > facebook > website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c663fba5-1553-4a8f-9cc8-e26430cc3dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_city(row):\n",
    "    if pd.notnull(row['city_y']): \n",
    "        return row['city_y']\n",
    "    if pd.notnull(row['city_x']): \n",
    "        return row['city_x']\n",
    "    if pd.notnull(row['main_city']): \n",
    "        return row['main_city']\n",
    "    return np.nan\n",
    "\n",
    "def choose_zipcode(row): \n",
    "    if pd.notnull(row['zip_code_y']): \n",
    "        return row['zip_code_y']\n",
    "    if pd.notnull(row['zip_code_x']): \n",
    "        return row['zip_code_x']\n",
    "    return np.nan\n",
    "\n",
    "df_merged['city'] = df_merged.apply(choose_city, axis=1)\n",
    "df_merged['zip_code'] = df_merged.apply(choose_zipcode, axis=1)\n",
    "df_merged.drop(columns=['city_y', 'city_x','main_city','zip_code_x','zip_code_y'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec25d29-8867-4437-8703-acbe71545564",
   "metadata": {},
   "source": [
    "7) Address: for the address I am going to choose address_y > raw_address bc it is more specific. If it doesnt exist I will use raw_address. If it doesnt exist I will use address_x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e79a622e-d877-48d9-ab60-091a5d3b7feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_address(row):\n",
    "    if pd.notnull(row['address_y']): \n",
    "        return row['address_y']\n",
    "    if pd.notnull(row['raw_address']): \n",
    "        return row['raw_address']\n",
    "    if pd.notnull(row['address_x']): \n",
    "        return row['address_x']\n",
    "    return np.nan\n",
    "\n",
    "df_merged['address'] = df_merged.apply(choose_address, axis=1)\n",
    "df_merged.drop(columns=['address_y', 'address_x','raw_address'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa382a1-a388-4d43-ac64-20524ec74b99",
   "metadata": {},
   "source": [
    "Finally, I will format the dataset so that every row has the same format.\n",
    "I will format the phone numbers this way: +{country_prefix}{number}. So, I delete all the chr that are not numbers. Some numbers have the country prefix but dont have the +, some have just the number. I use phonenumbers and pycountry to find the correct prefix based on the country name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88c3cbd9-5a92-4000-9cf4-fd15a1993c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['legal_name'] = df_merged['legal_name'].apply(lambda x: x.title() if isinstance(x, str) else x)\n",
    "df_merged['country'] = df_merged['country'].apply(lambda x: x.title() if isinstance(x, str) else x)\n",
    "df_merged['city'] = df_merged['city'].apply(lambda x: x.title() if isinstance(x, str) else x)\n",
    "df_merged['region'] = df_merged['region'].apply(lambda x: x.title() if isinstance(x, str) else x)\n",
    "df_merged['address'] = df_merged['address'].apply(lambda x: x.title() if isinstance(x, str) else x)\n",
    "\n",
    "df_merged['phone']=df_merged['phone'].str.replace(' ','').str.replace('(','').str.replace(')','').str.replace('-','')\n",
    "\n",
    "import phonenumbers\n",
    "\n",
    "def get_phone_prefix(country_name):\n",
    "    try:\n",
    "        country = pycountry.countries.lookup(country_name)\n",
    "        code = country.alpha_2\n",
    "        return  str(phonenumbers.country_code_for_region(code))\n",
    "    except LookupError:\n",
    "        return False\n",
    "        \n",
    "def normalize_phone(row):\n",
    "    if pd.notnull(row['phone']):\n",
    "        if row['phone'].startswith('+'):\n",
    "            return row['phone']\n",
    "        if pd.notnull(row['country']):\n",
    "            prefix = get_phone_prefix(row['country'])\n",
    "            if prefix:\n",
    "                if row['phone'].startswith(prefix):\n",
    "                    return '+'+row['phone']\n",
    "                return '+'+prefix+row['phone']\n",
    "    return row['phone']\n",
    "\n",
    "df_merged['phone'] = df_merged.apply(normalize_phone, axis=1)\n",
    "df_merged = df_merged.drop(df_merged.index[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e98f65-80ac-4250-abe6-868ce8698e81",
   "metadata": {},
   "source": [
    "I create the final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3c7fb90-4266-4470-bd58-d355c33619ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv('datasets/final_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
